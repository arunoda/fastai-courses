{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 3 - Plannet\n",
    "\n",
    "This is based on a [kaggle dataset](https://www.kaggle.com/c/planet-understanding-the-amazon-from-space) where we are going to analyze a set of sat images.<br/>\n",
    "In that each image is classified with multiple lables. So, we need to identify them properly.\n",
    "\n",
    "## Downloading the dataset\n",
    "\n",
    "For that we need to install the kaggle API download data like this: <br/>\n",
    "First of all, we also need to install 7z support.\n",
    "\n",
    "```shell\n",
    "sudo apt-get install p7zip-full\n",
    "mkdir -p ~/data/planet\n",
    "cd ~/data/planet\n",
    "kaggle competitions download -c planet-understanding-the-amazon-from-space -f train_v2.csv\n",
    "kaggle competitions download -c planet-understanding-the-amazon-from-space -f train-jpg.tar.7z\n",
    "\n",
    "unzip train_v2.csv\n",
    "7z e train-jpg.tar.7z\n",
    "tar xf train-jpg.tar\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai import *\n",
    "from fastai.vision import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect Data\n",
    "\n",
    "Now we symlink this data directory this directory. <br/>\n",
    "So, we can inspect it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('data/planet/train_v2.csv'),\n",
       " PosixPath('data/planet/test-jpg'),\n",
       " PosixPath('data/planet/__MACOSX'),\n",
       " PosixPath('data/planet/test-jpg.tar.7z'),\n",
       " PosixPath('data/planet/train-jpg.tar.7z'),\n",
       " PosixPath('data/planet/test-jpg.tar'),\n",
       " PosixPath('data/planet/train-jpg.tar'),\n",
       " PosixPath('data/planet/train_v2.csv.zip'),\n",
       " PosixPath('data/planet/train-jpg')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = Path('data/planet'); PATH.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_name,tags\r\n",
      "train_0,haze primary\r\n",
      "train_1,agriculture clear primary water\r\n",
      "train_2,clear primary\r\n",
      "train_3,clear primary\r\n",
      "train_4,agriculture clear habitation primary road\r\n",
      "train_5,haze primary water\r\n",
      "train_6,agriculture clear cultivation primary water\r\n",
      "train_7,haze primary\r\n",
      "train_8,agriculture clear cultivation primary\r\n"
     ]
    }
   ],
   "source": [
    "train_csv_path=PATH/'train_v2.csv'\n",
    "!head {train_csv_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each images has multiple tags.<br/>\n",
    "Now let's have a look some image files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('data/planet/train-jpg/train_33634.jpg'),\n",
       " PosixPath('data/planet/train-jpg/train_14804.jpg'),\n",
       " PosixPath('data/planet/train-jpg/train_22880.jpg'),\n",
       " PosixPath('data/planet/train-jpg/train_20126.jpg'),\n",
       " PosixPath('data/planet/train-jpg/train_26330.jpg')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_image_path = PATH/'train-jpg'\n",
    "train_fnames = train_image_path.ls()\n",
    "train_fnames[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we've some idea of our data. So, based on that, we can create a DataBunch object and use that inside the learner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
